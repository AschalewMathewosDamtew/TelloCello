{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Bearer Id               Start  Start ms                 End  \\\n",
      "0  13114483460844900352 2019-04-04 12:01:18     770.0 2019-04-25 14:35:31   \n",
      "1  13114483482878900224 2019-04-09 13:04:04     235.0 2019-04-25 08:15:48   \n",
      "2  13114483484080500736 2019-04-09 17:42:11       1.0 2019-04-25 11:58:13   \n",
      "3  13114483485442799616 2019-04-10 00:31:25     486.0 2019-04-25 07:36:35   \n",
      "4  13114483499480700928 2019-04-12 20:10:23     565.0 2019-04-25 10:40:32   \n",
      "\n",
      "   End ms  Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0   662.0  1823652.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1   606.0  1365104.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2   652.0  1361762.0  2.082003e+14   3.376063e+10  3.528151e+13   \n",
      "3   171.0  1321509.0  2.082014e+14   3.375034e+10  3.535661e+13   \n",
      "4   954.0  1089009.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "  Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0   9164566995485190  ...          15854611.0           2501332.0   \n",
      "1            L77566A  ...          20247395.0          19111729.0   \n",
      "2            D42335A  ...          19725661.0          14699576.0   \n",
      "3            T21824A  ...          21388122.0          15146643.0   \n",
      "4            D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "              Bearer Id               Start  Start ms                 End  \\\n",
      "0  13114483460844900352 2019-04-04 12:01:18     770.0 2019-04-25 14:35:31   \n",
      "1  13114483482878900224 2019-04-09 13:04:04     235.0 2019-04-25 08:15:48   \n",
      "2  13114483484080500736 2019-04-09 17:42:11       1.0 2019-04-25 11:58:13   \n",
      "3  13114483485442799616 2019-04-10 00:31:25     486.0 2019-04-25 07:36:35   \n",
      "4  13114483499480700928 2019-04-12 20:10:23     565.0 2019-04-25 10:40:32   \n",
      "\n",
      "   End ms  Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0   662.0  1823652.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1   606.0  1365104.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2   652.0  1361762.0  2.082003e+14   3.376063e+10  3.528151e+13   \n",
      "3   171.0  1321509.0  2.082014e+14   3.375034e+10  3.535661e+13   \n",
      "4   954.0  1089009.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "  Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0   9164566995485190  ...          15854611.0           2501332.0   \n",
      "1            L77566A  ...          20247395.0          19111729.0   \n",
      "2            D42335A  ...          19725661.0          14699576.0   \n",
      "3            T21824A  ...          21388122.0          15146643.0   \n",
      "4            D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load engagement data from Task 2\n",
    "engagement_data = pd.read_excel('../data/telecom_data.xlsx')\n",
    "\n",
    "# Load experience data from Task 3 (as we are assuming no clusters exist yet)\n",
    "experience_data = pd.read_excel('../data/telecom_data.xlsx')\n",
    "\n",
    "# Inspect the data\n",
    "print(engagement_data.head())\n",
    "print(experience_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "from load_data import load_data_from_postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\biement fanteye\\Desktop\\TelloCello\\scripts\\load_data.py:35: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the data.\n"
     ]
    }
   ],
   "source": [
    "# Define your SQL query\n",
    "query = \"SELECT * FROM xdr_data;\" # Replace with your actual table name.\n",
    "\n",
    "# Load data from PostgreSQL\n",
    "df = load_data_from_postgres(query)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "if df is not None:\n",
    "    print(\"Successfully loaded the data.\")\n",
    "else:\n",
    "    print(\"Failed to load data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\biement fanteye\\Desktop\\TelloCello\\scripts\\load_data.py:35: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded engagement data.\n",
      "Successfully loaded experience data.\n"
     ]
    }
   ],
   "source": [
    "# Define your SQL queries for engagement and experience data\n",
    "query_engagement = \"SELECT * FROM xdr_data;\"  # Replace with the actual table name for engagement data\n",
    "query_experience = \"SELECT * FROM xdr_data;\"  # Replace with the actual table name for experience data\n",
    "\n",
    "# Load data from PostgreSQL\n",
    "engagement_data = load_data_from_postgres(query_engagement)\n",
    "experience_data = load_data_from_postgres(query_experience)\n",
    "\n",
    "# Inspect the data\n",
    "if engagement_data is not None:\n",
    "    print(\"Successfully loaded engagement data.\")\n",
    "else:\n",
    "    print(\"Failed to load engagement data.\")\n",
    "\n",
    "if experience_data is not None:\n",
    "    print(\"Successfully loaded experience data.\")\n",
    "else:\n",
    "    print(\"Failed to load experience data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MSISDN/Number  engagement_cluster  engagement_score\n",
      "0   3.366496e+10                   1          0.521900\n",
      "1   3.368185e+10                   0          2.040323\n",
      "2   3.376063e+10                   1          1.204255\n",
      "3   3.375034e+10                   0          2.492466\n",
      "4   3.369980e+10                   0          1.378744\n"
     ]
    }
   ],
   "source": [
    "# Task 4.1: Use alternative engagement features\n",
    "engagement_features = ['Total UL (Bytes)', 'Total DL (Bytes)', 'Activity Duration DL (ms)', 'Activity Duration UL (ms)']\n",
    "\n",
    "# Fill NaN values with the mean of each column\n",
    "engagement_data[engagement_features] = engagement_data[engagement_features].fillna(engagement_data[engagement_features].mean())\n",
    "\n",
    "# Standardize the engagement features\n",
    "scaler = StandardScaler()\n",
    "engagement_scaled = scaler.fit_transform(engagement_data[engagement_features])\n",
    "\n",
    "# Perform KMeans clustering (initial clustering for engagement)\n",
    "kmeans_engagement = KMeans(n_clusters=3, random_state=42)\n",
    "engagement_data['engagement_cluster'] = kmeans_engagement.fit_predict(engagement_scaled)\n",
    "\n",
    "# Get cluster centers and calculate distance to least engaged cluster\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "least_engaged_cluster = np.argmin(kmeans_engagement.cluster_centers_.sum(axis=1))\n",
    "engagement_data['engagement_score'] = euclidean_distances(engagement_scaled, [kmeans_engagement.cluster_centers_[least_engaged_cluster]]).flatten()\n",
    "\n",
    "# Inspect engagement data\n",
    "print(engagement_data[['MSISDN/Number', 'engagement_cluster', 'engagement_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bearer Id', 'Start', 'Start ms', 'End', 'End ms', 'Dur. (ms)', 'IMSI',\n",
       "       'MSISDN/Number', 'IMEI', 'Last Location Name', 'Avg RTT DL (ms)',\n",
       "       'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)',\n",
       "       'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)',\n",
       "       'DL TP < 50 Kbps (%)', '50 Kbps < DL TP < 250 Kbps (%)',\n",
       "       '250 Kbps < DL TP < 1 Mbps (%)', 'DL TP > 1 Mbps (%)',\n",
       "       'UL TP < 10 Kbps (%)', '10 Kbps < UL TP < 50 Kbps (%)',\n",
       "       '50 Kbps < UL TP < 300 Kbps (%)', 'UL TP > 300 Kbps (%)',\n",
       "       'HTTP DL (Bytes)', 'HTTP UL (Bytes)', 'Activity Duration DL (ms)',\n",
       "       'Activity Duration UL (ms)', 'Dur. (ms).1', 'Handset Manufacturer',\n",
       "       'Handset Type', 'Nb of sec with 125000B < Vol DL',\n",
       "       'Nb of sec with 1250B < Vol UL < 6250B',\n",
       "       'Nb of sec with 31250B < Vol DL < 125000B',\n",
       "       'Nb of sec with 37500B < Vol UL',\n",
       "       'Nb of sec with 6250B < Vol DL < 31250B',\n",
       "       'Nb of sec with 6250B < Vol UL < 37500B',\n",
       "       'Nb of sec with Vol DL < 6250B', 'Nb of sec with Vol UL < 1250B',\n",
       "       'Social Media DL (Bytes)', 'Social Media UL (Bytes)',\n",
       "       'Google DL (Bytes)', 'Google UL (Bytes)', 'Email DL (Bytes)',\n",
       "       'Email UL (Bytes)', 'Youtube DL (Bytes)', 'Youtube UL (Bytes)',\n",
       "       'Netflix DL (Bytes)', 'Netflix UL (Bytes)', 'Gaming DL (Bytes)',\n",
       "       'Gaming UL (Bytes)', 'Other DL (Bytes)', 'Other UL (Bytes)',\n",
       "       'Total UL (Bytes)', 'Total DL (Bytes)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experience Data with Clusters and Scores:\n",
      "   MSISDN/Number  experience_cluster  experience_score\n",
      "0   3.366496e+10                   0          0.561880\n",
      "1   3.368185e+10                   0          0.555890\n",
      "2   3.376063e+10                   0          0.552732\n",
      "3   3.375034e+10                   0          0.551151\n",
      "4   3.369980e+10                   0          0.552732\n"
     ]
    }
   ],
   "source": [
    "# Define experience features\n",
    "experience_features = ['Avg RTT DL (ms)', 'Avg Bearer TP DL (kbps)', 'TCP DL Retrans. Vol (Bytes)']\n",
    "\n",
    "# Fill missing values with the mean of each column\n",
    "experience_data[experience_features] = experience_data[experience_features].fillna(experience_data[experience_features].mean())\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "experience_scaled = scaler.fit_transform(experience_data[experience_features])\n",
    "\n",
    "# Perform KMeans clustering for experience\n",
    "kmeans_experience = KMeans(n_clusters=3, random_state=42)\n",
    "experience_data['experience_cluster'] = kmeans_experience.fit_predict(experience_scaled)\n",
    "\n",
    "# Get cluster centers and calculate distance to the worst experience cluster\n",
    "worst_experience_cluster = np.argmin(kmeans_experience.cluster_centers_.sum(axis=1))\n",
    "experience_data['experience_score'] = np.linalg.norm(experience_scaled - kmeans_experience.cluster_centers_[worst_experience_cluster], axis=1)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "print(\"\\nExperience Data with Clusters and Scores:\")\n",
    "print(experience_data[['MSISDN/Number', 'experience_cluster', 'experience_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in merged data:\n",
      "MSISDN/Number       1136356\n",
      "engagement_score          0\n",
      "experience_score          0\n",
      "dtype: int64\n",
      "        MSISDN/Number  engagement_score  experience_score  satisfaction_score\n",
      "484883   3.366232e+10          0.644179        173.100680           86.872430\n",
      "484480   3.366087e+10          2.061627        115.384950           58.723288\n",
      "691514   3.366087e+10          0.718562        115.384950           58.051756\n",
      "50500    3.368369e+10          1.669842         97.877180           49.773511\n",
      "751960   3.366773e+10         18.738119         31.741629           25.239874\n",
      "14688    3.376264e+10         16.707330         32.175261           24.441295\n",
      "388562   3.376094e+10          0.760631         48.040095           24.400363\n",
      "507915   3.366045e+10         11.744362         37.025443           24.384902\n",
      "8831     3.366045e+10         11.735380         37.025443           24.380412\n",
      "405353   3.360679e+10          0.456561         46.752673           23.604617\n"
     ]
    }
   ],
   "source": [
    "# Merge engagement and experience data on user ID\n",
    "merged_data = pd.merge(engagement_data[['MSISDN/Number', 'engagement_score']], \n",
    "                       experience_data[['MSISDN/Number', 'experience_score']], \n",
    "                       on='MSISDN/Number', how='inner')  # Use 'inner' join to keep only matching records\n",
    "\n",
    "# Check for any remaining missing values in the merged data\n",
    "print(\"Missing values in merged data:\")\n",
    "print(merged_data.isnull().sum())\n",
    "\n",
    "# Remove rows with missing values\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "# Calculate satisfaction score as average of engagement and experience score\n",
    "merged_data['satisfaction_score'] = (merged_data['engagement_score'] + merged_data['experience_score']) / 2\n",
    "\n",
    "# Find top 10 most satisfied customers\n",
    "top_10_satisfied = merged_data.nlargest(10, 'satisfaction_score')\n",
    "print(top_10_satisfied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3.472490325829538e-29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Use engagement and experience scores to predict satisfaction score\n",
    "X = merged_data[['engagement_score', 'experience_score']]\n",
    "y = merged_data['satisfaction_score']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the regression model\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict satisfaction score\n",
    "y_pred = reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MSISDN/Number  engagement_score  experience_score  \\\n",
      "score_cluster                                                      \n",
      "0               3.810032e+10          1.827094          0.833340   \n",
      "1               3.368623e+10          4.413590         22.129761   \n",
      "\n",
      "               satisfaction_score  \n",
      "score_cluster                      \n",
      "0                        1.330217  \n",
      "1                       13.271675  \n"
     ]
    }
   ],
   "source": [
    "# Perform KMeans clustering on engagement and experience scores\n",
    "kmeans_scores = KMeans(n_clusters=2, random_state=42)\n",
    "merged_data['score_cluster'] = kmeans_scores.fit_predict(merged_data[['engagement_score', 'experience_score']])\n",
    "\n",
    "# Inspect the clusters\n",
    "print(merged_data.groupby('score_cluster').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               avg_satisfaction  avg_experience\n",
      "score_cluster                                  \n",
      "0                      1.289463        0.954016\n",
      "1                     50.634934       99.697103\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the average satisfaction and experience score per cluster\n",
    "cluster_aggregates = merged_data.groupby('score_cluster').agg(\n",
    "    avg_satisfaction=('satisfaction_score', 'mean'),\n",
    "    avg_experience=('experience_score', 'mean')\n",
    ")\n",
    "print(cluster_aggregates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tellocello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
